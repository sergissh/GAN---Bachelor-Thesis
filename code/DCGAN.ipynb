{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3995,"status":"ok","timestamp":1687852302665,"user":{"displayName":"Sergi Sánchez Hernández","userId":"17300515067516907224"},"user_tz":-120},"id":"135b377f"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15153,"status":"ok","timestamp":1687852317810,"user":{"displayName":"Sergi Sánchez Hernández","userId":"17300515067516907224"},"user_tz":-120},"id":"t7lCISXwlGH3","outputId":"2bf405df-ef7b-43b9-cbfc-dc9569b4d754"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","paths = {\n","    \"MNIST_30000\" : \"/content/drive/MyDrive/ColabNotebooks/TFG/datos/MNIST_30000.zip\",\n","    \"MNIST_70000\" : \"/content/drive/MyDrive/ColabNotebooks/TFG/datos/MNIST_70000.zip\",\n","    \"CELEBA_30000\" : \"/content/drive/MyDrive/ColabNotebooks/TFG/datos/CELEBA_30000.zip\",\n","    \"CELEBA_70000\" : \"/content/drive/MyDrive/ColabNotebooks/TFG/datos/CELEBA_70000.zip\"\n","}\n","\n","#Cambiar directorio donde guardar los resultados\n","dirs = {\n","    \"mnist_30000\" : './datasets/MNIST_30000/',\n","    \"mnist_70000\" : './datasets/MNIST_70000/',\n","    \"celeba_30000\" : './datasets/CELEBA_30000/',\n","    \"celeba_70000\" : './datasets/CELEBA_70000/',\n","    \"results_folder\" : \"/content/drive/MyDrive/ColabNotebooks/TFG/checkpoints/DCGAN/CELEBA_70000/\"\n","}\n","\n","path = paths[\"CELEBA_70000\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"I3669om_7jeN"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/datasets\n","/content\n"]}],"source":["!mkdir datasets\n","%cd datasets\n","%cp \"{path}\" .\n","!unzip -q CELEBA_70000.zip\n","%rm CELEBA_70000.zip\n","%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e47gsWhWB9R1"},"outputs":[],"source":["!nvidia-smi\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwfyx9p5eTuy"},"outputs":[],"source":["!rm -rf ./logs/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8867ae2e"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, channels_img, features_d):\n","        super(Discriminator, self).__init__()\n","        self.disc = nn.Sequential(\n","            #Input: N x channels_img x 64 x 64\n","            nn.Conv2d(\n","                channels_img, features_d, kernel_size=4, stride=2, padding=1\n","            ),\n","            nn.LeakyReLU(0.2),\n","            self._block(features_d, features_d*2, 4, 2, 1), #16 x 16\n","            self._block(features_d*2, features_d*4, 4, 2, 1),#8 x 8\n","            self._block(features_d*4, features_d*8, 4, 2, 1),#4 x 4\n","            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=2, padding=0), #1x1\n","            nn.Sigmoid()\n","        )\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.Conv2d(\n","                in_channels,\n","                out_channels,\n","                kernel_size,\n","                stride,\n","                padding,\n","                bias=False\n","            ),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2)\n","        )\n","\n","    def forward(self, x):\n","        return self.disc(x)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"25084950"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, z_dim, channels_img, features_g):\n","        super(Generator, self).__init__()\n","        self.gen = nn.Sequential(\n","            #Input: N x z_dim x 1 x 1\n","            self._block(z_dim, features_g*16, 4, 1, 0),\n","            self._block(features_g*16, features_g*8, 4, 2, 1), #8x8\n","            self._block(features_g*8, features_g*4, 4, 2, 1), #16 x 16\n","            self._block(features_g*4, features_g*2, 4, 2, 1), # 32x32\n","            nn.ConvTranspose2d(\n","                features_g*2, channels_img, kernel_size=4, stride=2, padding=1\n","            ), # 64x64\n","            nn.Tanh(), #[-1, 1]\n","        )\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels,\n","                out_channels,\n","                kernel_size,\n","                stride,\n","                padding,\n","                bias = False\n","            ),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","        )\n","    def forward(self, x):\n","        return self.gen(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0546cc69"},"outputs":[],"source":["def initialize_weights(model):\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2342bc0f"},"outputs":[],"source":["def test():\n","    N, in_channels, H, W, = 8, 3, 64, 64\n","    z_dim = 100\n","    x = torch.randn((N, in_channels, H, W))\n","    disc = Discriminator(in_channels, 8)\n","    initialize_weights(disc)\n","    assert disc(x).shape == (N, 1, 1, 1)\n","    gen = Generator(z_dim, in_channels, 8)\n","    initialize_weights(gen)\n","    z = torch.randn((N, z_dim, 1, 1))\n","    assert gen(z).shape == (N, in_channels, H, W)\n","    print(\"Success\")\n","test()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8030ba79"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","%matplotlib inline\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transform\n","import torchvision.utils as torch_utils\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter\n","import os as os\n","from PIL import Image\n","from natsort import natsorted\n","from torchvision.models.feature_extraction import get_graph_node_names\n","from torchvision.models.feature_extraction import create_feature_extractor\n","from scipy.linalg import sqrtm\n","from tqdm import tqdm\n","import numpy as np\n","import zipfile\n","import gc\n","import time\n","from scipy.stats import entropy\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3EbhQ8sDEMf"},"outputs":[],"source":["from torchvision.models.inception import inception_v3\n","import copy\n","\n","class GAN_Evaluator(object):\n","    def __init__(self, device, num_images_real, num_images_fake, IS_splits) -\u003e None:\n","        self.min_resolution = 75\n","        self.device = device\n","\n","        if device.type == 'cuda':\n","            self.dtype = torch.cuda.FloatTensor\n","        else:\n","            if torch.cuda.is_available():\n","                print(\"You have cuda device, try setting cuda=True for accelearte the training\")\n","            self.dtype = torch.FloatTensor\n","\n","        self.inception_encoder = inception_v3(weights=\"DEFAULT\", transform_input=False).type(self.dtype)\n","        self.inception_classifier = copy.deepcopy(self.inception_encoder.fc)\n","        self.inception_classifier.eval()\n","        self.inception_encoder.fc = torch.nn.Identity()\n","        self.inception_encoder.eval()\n","        self.upsample = torch.nn.Upsample(size=(299, 299),\n","            mode='bilinear').type(self.dtype)\n","\n","        self.num_images_real = num_images_real\n","        self.num_images_fake = num_images_fake\n","        self.activation_vec_real = np.empty((self.num_images_real, 2048))\n","        self.activation_vec_fake = np.empty((self.num_images_fake, 2048))\n","        self.prediction_vec_fake = np.empty((self.num_images_fake, 1000))\n","        self.vec_real_pointer = 0\n","        self.vec_fake_pointer = 0\n","\n","        self.IS_splits = IS_splits\n","\n","    def get_real_activations(self, n):\n","      return self.activation_vec_real[:n]\n","\n","    def get_fake_activations(self, n):\n","      return self.activation_vec_fake[:n]\n","\n","    def normalize(self, image, dynamic_range = [0, 1]):\n","        #assert len(dynamic_range) == 2\n","\n","        x1, x2 = image.min(), image.max()\n","        y1, y2 = dynamic_range[0], dynamic_range[1]\n","\n","        slope = (y2 - y1) / (x2 - x1)\n","        offset = (y1 * x2 - y2 * x1) / (x2 - x1)\n","\n","        image = image * slope + offset\n","        image = image.clip(y1, y2)\n","        return image\n","\n","    def get_distance(self, v1, v2):\n","      return np.linalg.norm(v1-v2)\n","\n","    def get_radius(self, v, points):\n","      dist = np.linalg.norm(np.array([v] * points.shape[0]) - points, axis = 1)\n","      dist = sorted(dist)\n","      return dist\n","\n","    def get_manifold(self, points, k=3):\n","      radius = np.zeros([self.vec_fake_pointer])\n","      for i in range(self.vec_fake_pointer):\n","        radius[i] = self.get_radius(points[i], points)[k]\n","      return {\n","          \"radius\": radius,\n","          \"len\": points.shape[0],\n","          \"points\": points\n","      }\n","\n","    def in_manifold(self, activations, manifold):\n","        for i in range(manifold[\"len\"]):\n","            if np.linalg.norm(activations-manifold[\"points\"][i]) \u003c= manifold[\"radius\"][i]:\n","                return 1\n","        return 0\n","\n","    def getPrecRecall(self):\n","      manifold_real = self.get_manifold(self.activation_vec_real[:self.vec_fake_pointer])\n","      manifold_fake = self.get_manifold(self.activation_vec_fake[:self.vec_fake_pointer])\n","      precision = 0\n","      for i in range(self.vec_fake_pointer):\n","        precision += self.in_manifold(self.activation_vec_fake[i], manifold_real)\n","      precision = precision / self.vec_fake_pointer\n","\n","      recall = 0\n","      for i in range(self.vec_fake_pointer):\n","        recall += self.in_manifold(self.activation_vec_real[i], manifold_fake)\n","      recall = recall / self.vec_fake_pointer\n","\n","      return precision, recall\n","\n","\n","    def fill_real_image_batch(self, real_batch):\n","        transforms_norm = transform.Compose([\n","                transform.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","            ])\n","        batch_size = real_batch.shape[0]\n","        real_batch = self.normalize(real_batch)\n","        real_batch = real_batch.type(torch.FloatTensor).to(self.device)\n","\n","        _, C, H, W = real_batch.shape\n","        if H \u003c self.min_resolution or W \u003c self.min_resolution:\n","            real_batch = self.upsample(real_batch)\n","\n","        if C == 1:\n","            transforms = transform.Compose([\n","                transform.Lambda(lambda x: torch.cat([x, x, x], 1)),\n","            ])\n","            real_batch = transforms(real_batch)\n","\n","        # Get activations.\n","        with torch.no_grad():\n","            real_batch = transforms_norm(real_batch)\n","            activations_real = self.inception_encoder(real_batch)\n","        self.activation_vec_real[self.vec_real_pointer:self.vec_real_pointer +\n","                                 batch_size] = activations_real.cpu().numpy()\n","        self.vec_real_pointer += batch_size\n","\n","        return\n","\n","    def fill_fake_image_batch(self, fake_batch, compute):\n","        batch_size = fake_batch.shape[0]\n","        fake_batch = self.normalize(fake_batch)\n","        fake_batch = fake_batch.type(torch.FloatTensor).to(self.device)\n","\n","        _, C, H, W = fake_batch.shape\n","        if H \u003c self.min_resolution or W \u003c self.min_resolution:\n","            fake_batch = self.upsample(fake_batch)\n","\n","        if C == 1:\n","            transforms = transform.Compose([\n","                transform.Lambda(lambda x: torch.cat([x, x, x], 1)),\n","            ])\n","            fake_batch = transforms(fake_batch)\n","\n","        with torch.no_grad():\n","            activations_fake = self.inception_encoder(fake_batch)\n","            preds_fake = self.inception_classifier(activations_fake)\n","            probs_fake = torch.nn.functional.softmax(preds_fake,\n","                                                    dim=1).data.cpu().numpy()\n","        self.activation_vec_fake[self.vec_fake_pointer:self.vec_fake_pointer +\n","                                 batch_size] = activations_fake.cpu().numpy()\n","        self.prediction_vec_fake[self.vec_fake_pointer:self.vec_fake_pointer +\n","                                 batch_size] = probs_fake\n","        self.vec_fake_pointer += batch_size\n","\n","        if compute:\n","          IS_mean, IS_std = self.getInceptionScore()\n","          Fid = self.getFrechetInceptionDistance()\n","          return IS_mean, IS_std, Fid\n","        return\n","\n","    def clear_fake_images(self):\n","        self.activation_vec_fake = np.empty((self.num_images_fake, 2048))\n","        self.prediction_vec_fake = np.empty((self.num_images_fake, 1000))\n","        self.vec_fake_pointer = 0\n","        return\n","\n","    def clear_real_images(self):\n","        self.activation_vec_real = np.empty((self.num_images_real, 2048))\n","        self.vec_real_pointer = 0\n","        return\n","\n","    def fill_fake_image_full(self, fake_images_loader):\n","        self.clear_fake_images()\n","        for fake_batch in tqdm(fake_images_loader):\n","            self.fill_fake_image_batch(fake_batch)\n","\n","        Is_mean, Is_std = self.getInceptionScore()\n","        Fid = self.getFrechetInceptionDistance()\n","\n","        return Is_mean, Is_std, Fid\n","\n","    def fill_real_image_full(self, real_images_loader):\n","        self.clear_real_images()\n","        for real_batch in tqdm(real_images_loader):\n","            self.fill_real_image_batch(real_batch)\n","\n","        return\n","\n","    def getInceptionScore(self):\n","        split_scores = []\n","\n","        for k in range(self.IS_splits):\n","            data = self.prediction_vec_fake[:self.vec_fake_pointer]\n","            part = data[k * (self.vec_fake_pointer // self.IS_splits): (k+1) * (self.vec_fake_pointer // self.IS_splits), :]\n","            py = np.mean(part, axis=0)\n","            scores = []\n","            for i in range(part.shape[0]):\n","                pyx = part[i, :]\n","                scores.append(entropy(pyx, py))\n","\n","            split_scores.append(np.exp(np.mean(scores)))\n","\n","        return np.mean(split_scores), np.std(split_scores)\n","\n","    def getFrechetInceptionDistance(self):\n","        real_activations = self.activation_vec_real[:self.vec_real_pointer]\n","        fake_activations = self.activation_vec_fake[:self.vec_fake_pointer]\n","\n","        mu1, sigma1 = real_activations.mean(axis=0), np.cov(real_activations, rowvar=False)\n","        mu2, sigma2 = fake_activations.mean(axis=0), np.cov(fake_activations, rowvar=False)\n","\n","        # calculate sum squared difference between means\n","        ssdiff = np.sum((mu1 - mu2)**2.0)\n","        # calculate sqrt of product between cov\n","        covmean = sqrtm(sigma1.dot(sigma2))\n","        # check and correct imaginary numbers from sqrt\n","        if np.iscomplexobj(covmean):\n","            covmean = covmean.real\n","        # calculate score\n","        fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n","\n","        return fid\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RDrOJZ06cpW"},"outputs":[],"source":["class CustomDataSet(Dataset):\n","    def __init__(self, main_dir, transform):\n","        self.main_dir = main_dir\n","        self.transform = transform\n","        all_imgs = os.listdir(main_dir)\n","        self.total_imgs = natsorted(all_imgs)\n","\n","    def __len__(self):\n","        return len(self.total_imgs)\n","\n","    def __getitem__(self, idx):\n","        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n","        #image = Image.open(img_loc).convert(\"RGB\")\n","        image = Image.open(img_loc)\n","        if self.transform:\n","          tensor_image = self.transform(image)\n","        return tensor_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJYVBiqvGR-9"},"outputs":[],"source":["from pickle import FALSE\n","import cv2 as cv2\n","class GAN_utils(object):\n","  def __init__(self, epochs, path, dataset):\n","    #Lists for storage Losses, FIDs and Inception Scores\n","    self.InceptionList, self.FIDList, self.generatorLoss, self.discriminatorLoss, self.epochs_time  = [], [], [], [], []\n","    self.gridImages = []\n","    self.num_epochs = epochs\n","    self.precision, self.recall = [], []\n","    self.path = path\n","    self.dataset = dataset\n","\n","  def getPrecision(self):\n","    return self.precision, self.recall\n","  def appendLosses(self, gen_loss, disc_loss):\n","    self.generatorLoss.append(gen_loss)\n","    self.discriminatorLoss.append(disc_loss)\n","\n","  def appendPrecisionRecall(self, prec, recall):\n","    self.precision.append(prec)\n","    self.recall.append(recall)\n","\n","  def appendInceptionScore(self, inception):\n","    self.InceptionList.append(inception)\n","\n","  def apendFid(self, fid):\n","    self.FIDList.append(fid)\n","\n","  def appendEpochTime(self, time):\n","    self.epochs_time.append(time)\n","\n","  def getTotalTrainingTime(self):\n","    return sum(self.epochs_time)\n","\n","  def appendImagesToGrid(self, img):\n","    self.gridImages.append(img)\n","\n","  def PrecisionRecall(self):\n","    save_path = self.path + \"PrecRecall2_chartt.png\"\n","    fig, ax = plt.subplots(figsize=(6,6))\n","    ax.plot(self.recall, self.precision)\n","    ax.set_xlabel('Recall')\n","    ax.set_ylabel('Precision')\n","    plt.savefig(save_path)\n","\n","  def plotLossesChart(self):\n","    save_path = self.path + \"losses_chartt.png\"\n","    plt.figure(figsize=(10,5))\n","    plt.title(\"DCGAN Loss Chart\")\n","    plt.plot(self.generatorLoss,label=\"Generator Loss\")\n","    plt.plot(self.discriminatorLoss,label=\"Discriminator Loss\")\n","    plt.xlabel(\"epochs\")\n","    plt.ylabel(\"Losses\")\n","    plt.legend()\n","    plt.savefig(save_path)\n","    plt.show()\n","\n","  def plotFidIsChart(self):\n","    save_path = self.path + \"FIDIS_chartt.png\"\n","    epoch_list = list(range(0,self.num_epochs))\n","    fig = plt.figure(figsize=(10, 4))\n","    ax = fig.add_subplot(1, 2, 1)\n","    ax.scatter(epoch_list, self.InceptionList, color='firebrick')\n","    ax.plot(epoch_list, self.InceptionList, color='firebrick')\n","    ax.set_ylabel('Inception Score (IS)')\n","    ax.set_xlabel('Epoch')\n","    ax.spines[['right', 'top']].set_visible(False)\n","    ax = fig.add_subplot(1, 2, 2)\n","    ax.scatter(epoch_list, self.FIDList, color='firebrick')\n","    ax.plot(epoch_list, self.FIDList, color='firebrick')\n","    ax.set_ylabel('Frechet Inception Distance (FID)')\n","    ax.set_xlabel('Epoch')\n","    ax.spines[['right', 'top']].set_visible(False)\n","    plt.tight_layout()\n","    plt.savefig(save_path)\n","    plt.show()\n","\n","  def getGeneratedImage(self, generator):\n","    gen.eval()\n","    with torch.no_grad():\n","      noise = torch.randn(1, Z_DIM, 1, 1).to(device)\n","      img = generator(noise)\n","    img = np.asarray(img.detach().cpu())\n","    img = np.squeeze(img, axis=0)\n","    img = np.transpose(img, (1, 2, 0))\n","    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n","    _, _, C = img.shape\n","    if C == 1:\n","      plt.imshow(img, cmap=\"gray\")\n","    else:\n","      plt.imshow(img)\n","\n","  def grid_animation(self, author):\n","    save_path = self.path + \"grid_animation.gif\"\n","    fig = plt.figure(figsize=(8,8))\n","    plt.axis('off')\n","    ims = [[plt.imshow(np.transpose(i, (1,2,0)), animated=True)] for i in self.gridImages]\n","    anim = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n","    plt.show()\n","    anim.save(save_path, dpi=80, writer=author)\n","\n","  def startSeed(self, seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","  def plotDataLoader(self, dataloader):\n","    # Plot some training images\n","    real_batch = next(iter(loader))\n","    plt.figure(figsize=(16,16))\n","    plt.axis(\"off\")\n","    plt.title(\"Training Images\")\n","    grid_images = torch_utils.make_grid(real_batch[:16].to(device).cpu(), normalize=True)\n","    grid_numpy = grid_images.numpy()\n","    grid_numpy2 = np.transpose(grid_numpy, (1, 2, 0))\n","    plt.imshow(grid_numpy2)\n","\n","  def save_checkpoint(self, epoch, gen, opt_gen, disc, opt_disc, loss_gen, loss_disc):\n","    save_path = self.path + \"epoch=\" + str(round(epoch, 4)) + \"%loss_disc=\" + str(round(loss_disc.item(), 4)) + \"%loss_gen=\" + str(round(loss_gen.item(), 4)) + \".pt\"\n","    torch.save({\n","        'epoch': epoch,\n","        'gen_state_dict': gen.state_dict(),\n","        'gen_optimizer_state_dict': opt_gen.state_dict(),\n","        'disc_state_dict': disc.state_dict(),\n","        'disc_optimizer_state_dict': opt_disc.state_dict(),\n","        'gen_loss': loss_gen,\n","        'disc_loss':loss_disc\n","      }, save_path)\n","\n","  def saveResults(self, actual_epoch):\n","    path_txt = self.path + \"results_epoch=\" + str(actual_epoch) + \".txt\"\n","    with open(path_txt, 'w') as f:\n","      f.write(\"Model: DCGAN  \\n\")\n","      f.write(\"Dataset: \" + self.dataset + \"\\n\")\n","      f.write(\"Epochs: \" + str(actual_epoch) + \"\\n\")\n","      f.write(\"Generator Losses: [\")\n","      for i in self.generatorLoss:\n","        f.write(str(i) + \", \")\n","      f.write(']\\n Discriminator Losses: [')\n","      for j in self.discriminatorLoss:\n","        f.write(str(j) + \", \")\n","      f.write('] \\n FIDs: [')\n","      for i in self.FIDList:\n","        f.write(str(i) + \", \")\n","      f.write(\" ]\\n Inception Scores: [\")\n","      for i in self.InceptionList:\n","        f.write(str(i) + \", \")\n","      f.write(\"] \\n Epoch Times: \")\n","      for i in self.epochs_time:\n","        f.write(str(i) + \", \")\n","      f.write(\"] \\n Total Time: \" + str(self.getTotalTrainingTime()) + \"\\n\")\n","      f.write(\"Precision: [\")\n","      for i in self.precision:\n","        f.write(str(i) + \", \")\n","      f.write(\"] \\n Recall: [\")\n","      for i in self.recall:\n","        f.write(str(i) + \", \")\n","      f.write(\"]\")\n","\n","  def saveFinalModel(self, model):\n","    torch.save(model.state_dict(), self.path + 'finalGenerator.pth')\n","\n","  def saveNImages(self, model, num_images=32):\n","    model.eval()\n","    with torch.no_grad():\n","      noise = torch.randn(num_images, Z_DIM, 1, 1).to(device)\n","      imgs = model(noise)\n","    imgs = imgs.detach().cpu().numpy()\n","    for i in range(imgs.shape[0]):\n","        img = np.transpose(imgs[i], (1, 2, 0))\n","        img = (img - np.min(img)) / (np.max(img) - np.min(img))\n","        img = np.asarray(img*255).astype(np.uint8)\n","        H, W, C = img.shape\n","        image_filename = self.path + \"/fake_images/gen_\" + str(i) + \".png\"\n","        if C == 1:\n","          cv2.imwrite(image_filename, img)\n","        else:\n","          img = Image.fromarray(img, \"RGB\")\n","          img.save(image_filename)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1a559e52"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","LEARNING_RATE = 2e-4\n","BATCH_SIZE = 128\n","IMAGE_SIZE = 64\n","CHANNELS_IMG = 3\n","Z_DIM = 100\n","NUM_EPOCHS = 50\n","FEATURES_DISC = 64\n","FEATURES_GEN = 64\n","\n","#Image List for Grid Animation\n","img_list=[]\n","\n","transforms = transform.Compose([\n","    transform.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","    transform.ToTensor(),\n","    transform.Normalize(\n","        [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n","    )\n","])\n","\n","utils = GAN_utils(NUM_EPOCHS, dirs[\"results_folder\"], \"CELEBA_70000\")\n","utils.startSeed(1)\n","\n","dataset = CustomDataSet(dirs['celeba_70000'], transform=transforms)\n","loader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True)\n","gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n","disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n","initialize_weights(gen)\n","initialize_weights(disc)\n","\n","opt_gen = optim.Adam(gen.parameters(), lr = LEARNING_RATE, betas=(0.5, 0.999))\n","opt_disc = optim.Adam(disc.parameters(), lr = LEARNING_RATE, betas=(0.5, 0.999))\n","criterion = nn.BCELoss()\n","\n","fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n","writer_real = SummaryWriter(f\"logs/real\")\n","writer_fake = SummaryWriter(f\"logs/fake\")\n","step = 0\n","\n","gen.train()\n","disc.train()\n","\n","evaluator = GAN_Evaluator(device=device,\n","    num_images_real=len(loader.dataset),\n","    num_images_fake=len(loader.dataset),\n","    IS_splits = 1)\n","evaluator.fill_real_image_full(loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJHojdWiV2fF"},"outputs":[],"source":["images = next(iter(loader))[:5]\n","grid_images = torch_utils.make_grid(images.to(device).cpu(), normalize=True, padding=2)\n","grid_numpy = grid_images.numpy()\n","grid_numpy2 = np.transpose(grid_numpy, (1, 2, 0))\n","plt.imshow(grid_numpy2)\n","plt.savefig('./bla.png')"]},{"cell_type":"markdown","metadata":{"id":"ypqG6R3LV69J"},"source":["### Visualize Grid of Real Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5U_y-J0bV4m_"},"outputs":[],"source":["utils.plotDataLoader(loader)"]},{"cell_type":"markdown","metadata":{"id":"KQuiZ-ZTWBu7"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxWw4dRBKSAB"},"outputs":[],"source":["FID_list, IS_list, GEN_loss_list, DISC_loss_list = [], [], [], []\n","for epoch in range(NUM_EPOCHS):\n","    utils.startSeed(1)\n","    init = time.time()\n","    for batch_idx, real in enumerate(loader):\n","        real = real.to(device)\n","        noise = torch.randn((BATCH_SIZE, Z_DIM, 1, 1)).to(device)\n","        fake = gen(noise)\n","\n","        ##TRAIN Discriminator\n","        disc_real = disc(real).reshape(-1)\n","        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n","        #disc_fake = disc(fake.detach()).reshape(-1)\n","        disc_fake = disc(fake.detach()).reshape(-1)\n","        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n","        disc.zero_grad()\n","        loss_disc.backward()\n","        opt_disc.step()\n","\n","        ##TRAIN Generator\n","        output = disc(fake).reshape(-1)\n","        loss_gen = criterion(output, torch.ones_like(output))\n","        gen.zero_grad()\n","        loss_gen.backward()\n","        opt_gen.step()\n","\n","        if batch_idx % 100 == 0:\n","            with torch.no_grad():\n","                fake = gen(fixed_noise)\n","\n","                img_grid_real = torchvision.utils.make_grid(\n","                    real[:32], normalize = True\n","                )\n","                img_grid_fake = torchvision.utils.make_grid(\n","                    fake[:32], normalize = True\n","                )\n","\n","                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n","                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n","\n","            utils.appendImagesToGrid(torch_utils.make_grid(fake.detach().cpu(), padding=2, normalize=True))\n","            step+=1\n","\n","\n","\n","    #Save Discriminator and Generator Losses\n","    utils.appendLosses(loss_gen.item(), loss_disc.item())\n","    #Calculate FID and IS\n","    for i in range(10):\n","      with torch.no_grad():\n","        z = torch.randn((100, Z_DIM, 1, 1)).to(device)\n","        fake_imgs = gen(z)\n","      if i == 9:\n","        IS_mean, IS_std, FID = evaluator.fill_fake_image_batch(fake_imgs, True)\n","      else:\n","        evaluator.fill_fake_image_batch(fake_imgs, False)\n","\n","    #Save IS and FID\n","    utils.appendInceptionScore(IS_mean)\n","    utils.apendFid(FID)\n","\n","    #If last parameter is True will plot during training\n","    if (epoch + 1) % 5 == 0:\n","      precision, recall = evaluator.getPrecRecall()\n","      utils.appendPrecisionRecall(precision, recall)\n","      print(\"Precision: {}, Recall: {}\".format(precision, recall))\n","\n","    #Save Checkpoint and Obtained Results in txt\n","    if (epoch + 1) % 15 == 0:\n","      utils.save_checkpoint(epoch, gen, opt_gen, disc, opt_disc, loss_gen, loss_disc)\n","      utils.saveResults(epoch)\n","\n","    #Clear activations of Fake Images\n","    evaluator.clear_fake_images()\n","\n","    #Calculate Epoch Time\n","    end = time.time()\n","    epoch_time = end - init\n","    utils.appendEpochTime(epoch_time)\n","\n","    #Print Information of the Epoch\n","    print(\n","      f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Time {epoch_time} Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}, Frechet Inception Distance: {FID:.4f}, Inception Score: {IS_mean:.4f}\"\n","    )\n","\n","#Print total Training Time\n","print(\"Total Training Time:\", utils.getTotalTrainingTime())\n","\n","#Save Results in txt\n","utils.saveResults(NUM_EPOCHS)\n"]},{"cell_type":"markdown","metadata":{"id":"p8m_ngMiT5X2"},"source":["### Losses Chart"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sp2ILMKUR2iG"},"outputs":[],"source":["utils.plotLossesChart()"]},{"cell_type":"markdown","metadata":{"id":"fHXsdC8ZT_AU"},"source":["### FID and IS Chart"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cODosS10TXdE"},"outputs":[],"source":["utils.plotFidIsChart()"]},{"cell_type":"markdown","metadata":{"id":"pJVVJk9fP3qV"},"source":["### Precision and Recall Chartt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5oX-EJjFP279"},"outputs":[],"source":["utils.PrecisionRecall()"]},{"cell_type":"markdown","metadata":{"id":"mGSK5GirWVqy"},"source":["### TensorBoard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmR_tbM2fnj1"},"outputs":[],"source":["#You can check the results in TensorBoard\n","%tensorboard --logdir logs"]},{"cell_type":"markdown","metadata":{"id":"fYKdvra_UJPN"},"source":["### Here you can generate Fake Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-TPx57GyUGNk"},"outputs":[],"source":["utils.getGeneratedImage(gen)"]},{"cell_type":"markdown","metadata":{"id":"QiiDb2KcVkcf"},"source":["### Save *Generator* Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivlEr3k_GrvH"},"outputs":[],"source":["utils.saveFinalModel(gen)"]},{"cell_type":"markdown","metadata":{"id":"rykL65d8Wy-2"},"source":["### Here you can save a grid animation of the fake images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvtw-ajHgnz7"},"outputs":[],"source":["author = \"Sergi Sanchez Hernandez\"\n","utils.grid_animation(author)\n"]},{"cell_type":"markdown","metadata":{"id":"W2eU2vDq0yV7"},"source":["\n","\n","```\n","# Tiene formato de código\n","```\n","\n","### Here you can generate and create Fake Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0RECxCX70whP"},"outputs":[],"source":["#num_images \u003c 129\n","utils.saveNImages(gen, 15)"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":5}